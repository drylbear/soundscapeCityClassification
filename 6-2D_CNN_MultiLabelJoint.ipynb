{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Flatten, Convolution2D, MaxPooling2D,Dropout, Reshape, LSTM, BatchNormalization,TimeDistributed\n",
    "from keras.layers import Conv2D\n",
    "from keras.optimizers import Adam #, RMSprop, SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from time import time\n",
    "\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import sys\n",
    "import h5py\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size =  16 #multiple of 1290/5 (recording length)\n",
    "nb_classes = 16\n",
    "rows, cols = 431, 128   \n",
    "nb_epoch = 200\n",
    "pool_size = (5,5)                  # size of pooling area for max pooling\n",
    "prob_drop_conv = 0.3                # drop probability for dropout @ conv layer\n",
    "prob_drop_hidden = 0.3              # drop probability for dropout @ fc layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " data sorted\n"
     ]
    }
   ],
   "source": [
    "#might need to rewrite these\n",
    "\n",
    "\n",
    "\n",
    "def fileLists():\n",
    "    trainlist=[]\n",
    "    validationlist=[]\n",
    "    testlist=[]\n",
    "    evalSetupFiles='..\\\\..\\\\CASAdatasets\\\\DCASE18_ASCT1\\\\TUT-urban-acoustic-scenes-2018-development\\\\evaluation_setup\\\\*.txt'\n",
    "    txtfilelist=glob.glob(evalSetupFiles)\n",
    "    for txt in txtfilelist:\n",
    "        if '_location' not in txt:\n",
    "            continue\n",
    "        with open(txt,'r') as evaltxtfile:\n",
    "            for line in evaltxtfile.readlines():\n",
    "                line=line.strip().split('\\t')[0]\n",
    "                if 'train' in txt:\n",
    "                    trainlist.append(line.replace('audio','logMelSpec').replace('.wav','_aggScenes.pckl').replace('/','\\\\'))\n",
    "                elif 'test' in txt:\n",
    "                    testlist.append(line.replace('audio','logMelSpec').replace('.wav','_aggScenes.pckl').replace('/','\\\\'))\n",
    "                else:\n",
    "                    validationlist.append(line.replace('audio','logMelSpec').replace('.wav','_aggScenes.pckl').replace('/','\\\\'))\n",
    "    print('trainfiles: ', str(len(trainlist)))\n",
    "    print('validationfiles: ', str(len(validationlist)))\n",
    "    print('testfiles: ', str(len(testlist)))\n",
    "    return trainlist,validationlist,testlist\n",
    "\n",
    "labelRef={'barcelona':0, 'helsinki':1, 'london':2, 'paris':3, 'stockholm':4, 'vienna':5, \n",
    "          'airport':6, 'shopping_mall':7,'metro_station':8,'street_pedestrian':9,'public_square':10,\n",
    "          'street_traffic':11,'tram':12,'bus':13,'metro':14,'park':15}\n",
    "\n",
    "def getData(flist):\n",
    "    pth='..\\\\..\\\\CASAdatasets\\\\DCASE18_ASCT1\\\\TUT-urban-acoustic-scenes-2018-development\\\\'\n",
    "    X_=np.zeros(((len(flist)),128,431))\n",
    "    Y_=np.zeros(((len(flist)),nb_classes))\n",
    "    for i,tfile in enumerate(flist):\n",
    "        with open(pth+tfile, \"rb\" ) as scenesample:\n",
    "            fv=pickle.load(scenesample)\n",
    "        X_[i,:,:]=fv\n",
    "        location=tfile.split('-')[1]\n",
    "        Y_[i,labelRef[location]]=1\n",
    "        scene=tfile.split('-')[0].replace('logMelSpec\\\\','')\n",
    "        Y_[i,labelRef[scene]]=1\n",
    "    return X_, Y_\n",
    "#trainlist,validationlist,testlist=fileLists()\n",
    "#X_train, Y_train = getData(trainlist)\n",
    "#X_val, Y_val = getData(validationlist)\n",
    "#X_test, Y_test = getData(testlist)\n",
    "\n",
    "print(' data sorted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 431, 32)      1600      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128, 431, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 216, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64, 216, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 216, 64)       100416    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64, 216, 64)       256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 108, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32, 108, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 108, 128)      32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 54, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 54, 128)       512       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16, 54, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 110592)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                7077952   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1040      \n",
      "=================================================================\n",
      "Total params: 7,215,056\n",
      "Trainable params: 7,214,480\n",
      "Non-trainable params: 576\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "###### Convolutional model\n",
    "def compileCRNN(cols,rows,nb_classes=1):\n",
    "\n",
    "    model = Sequential()\n",
    "    # conv1 layer\n",
    "    model.add(Conv2D(32, (7, 7), padding='same', activation='relu', input_shape=(cols,rows,1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=pool_size, strides=(2), padding='same'))\n",
    "    model.add(Dropout(prob_drop_conv))\n",
    "\n",
    "    # conv2 layer\n",
    "    model.add(Conv2D(64, (7, 7), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(4,7), strides=(2), padding='same'))\n",
    "    model.add(Dropout(prob_drop_conv))\n",
    "\n",
    "    # conv3 layer\n",
    "    model.add(Conv2D(128, (2, 2), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size, strides=(2), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(prob_drop_conv))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    # fc1 layer\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(prob_drop_hidden))\n",
    "    model.add(BatchNormalization())\n",
    "   \n",
    "    # fc2 layer\n",
    "    model.add(Dense(nb_classes, activation='sigmoid'))\n",
    "    opt = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "   \n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "model = compileCRNN(cols,rows,nb_classes=nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "#fold=1\n",
    "def train_network(model, model_name, X_train, Y_train, X_val, Y_val, nb_epoch, validationsplit_size, batchsize, early_stoping_patience, output_folder):\n",
    "    checkpointer = ModelCheckpoint(filepath=os.path.join(output_folder,model_name + '.hdf5'),save_best_only=True)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=early_stoping_patience)\n",
    "    tensorboard = TensorBoard(log_dir=\"logs\\\\{}\".format(time()))\n",
    "    Callbacks=[checkpointer,  tensorboard] #early_stopping,\n",
    "  #  print(samples)\n",
    "    steps=int(samples/batchsize)\n",
    "    validationsteps=int(validationsplit_size/batchsize)\n",
    "    history = model.fit(X_train, Y_train, epochs=nb_epoch, callbacks=Callbacks, batch_size=batch_size, validation_data=(X_val, Y_val), shuffle=True, verbose=1)\n",
    "    return history,model\n",
    "\n",
    "def buildModel(savemodelfilename, samples,model,X_train, Y_train,X_val, Y_val):\n",
    "    valSplit_size = int(samples/4)\n",
    "    early_stoping_patience=5\n",
    "    history,model = train_network(model, 'models\\\\multi_label', X_train, Y_train, X_val, Y_val, nb_epoch, valSplit_size, batch_size, early_stoping_patience,'.')\n",
    "    model.save_weights(savemodelfilename)\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainfiles:  6122\n",
      "validationfiles:  2518\n",
      "testfiles:  2518\n",
      "lists sorted\n",
      "data obtained\n",
      "(6122, 128, 431, 1) (2518, 128, 431, 1) (2518, 128, 431, 1)\n",
      "data sorted\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 128, 431, 32)      1600      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 128, 431, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 64, 216, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64, 216, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 64, 216, 64)       100416    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 64, 216, 64)       256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 32, 108, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 32, 108, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 32, 108, 128)      32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 16, 54, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 16, 54, 128)       512       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 16, 54, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 110592)            0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                7077952   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                1040      \n",
      "=================================================================\n",
      "Total params: 7,215,056\n",
      "Trainable params: 7,214,480\n",
      "Non-trainable params: 576\n",
      "_________________________________________________________________\n",
      "model compiled\n",
      "2019-04-09 16:15:50.406723\n",
      "Train on 6122 samples, validate on 2518 samples\n",
      "Epoch 1/200\n",
      "6122/6122 [==============================] - 26s 4ms/step - loss: 0.6879 - binary_accuracy: 0.5753 - val_loss: 0.6578 - val_binary_accuracy: 0.6512\n",
      "Epoch 2/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.5825 - binary_accuracy: 0.7811 - val_loss: 1.1565 - val_binary_accuracy: 0.6208\n",
      "Epoch 3/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.4719 - binary_accuracy: 0.8704 - val_loss: 3.6293 - val_binary_accuracy: 0.5415\n",
      "Epoch 4/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.3988 - binary_accuracy: 0.8740 - val_loss: 7.3671 - val_binary_accuracy: 0.4651\n",
      "Epoch 5/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.3621 - binary_accuracy: 0.8751 - val_loss: 5.3333 - val_binary_accuracy: 0.5868\n",
      "Epoch 6/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.3531 - binary_accuracy: 0.8750 - val_loss: 1.1520 - val_binary_accuracy: 0.8731\n",
      "Epoch 7/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.3428 - binary_accuracy: 0.8756 - val_loss: 2.0705 - val_binary_accuracy: 0.7662\n",
      "Epoch 8/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.3375 - binary_accuracy: 0.8759 - val_loss: 1.9516 - val_binary_accuracy: 0.7723\n",
      "Epoch 9/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.3324 - binary_accuracy: 0.8764 - val_loss: 1.8175 - val_binary_accuracy: 0.8202\n",
      "Epoch 10/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.3292 - binary_accuracy: 0.8765 - val_loss: 1.5300 - val_binary_accuracy: 0.8311\n",
      "Epoch 11/200\n",
      "6122/6122 [==============================] - 25s 4ms/step - loss: 0.3258 - binary_accuracy: 0.8770 - val_loss: 0.9590 - val_binary_accuracy: 0.8159\n",
      "Epoch 12/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.3236 - binary_accuracy: 0.8771 - val_loss: 2.3391 - val_binary_accuracy: 0.7626\n",
      "Epoch 13/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.3199 - binary_accuracy: 0.8776 - val_loss: 2.1260 - val_binary_accuracy: 0.7991\n",
      "Epoch 14/200\n",
      "6122/6122 [==============================] - 25s 4ms/step - loss: 0.3163 - binary_accuracy: 0.8780 - val_loss: 1.5334 - val_binary_accuracy: 0.8473\n",
      "Epoch 15/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.3137 - binary_accuracy: 0.8786 - val_loss: 1.1946 - val_binary_accuracy: 0.8427\n",
      "Epoch 16/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.3110 - binary_accuracy: 0.8783 - val_loss: 2.6337 - val_binary_accuracy: 0.7904\n",
      "Epoch 17/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.3087 - binary_accuracy: 0.8792 - val_loss: 2.6340 - val_binary_accuracy: 0.7632\n",
      "Epoch 18/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.3129 - binary_accuracy: 0.8788 - val_loss: 1.9951 - val_binary_accuracy: 0.8523\n",
      "Epoch 19/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.3029 - binary_accuracy: 0.8799 - val_loss: 6.2662 - val_binary_accuracy: 0.5074\n",
      "Epoch 20/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.2973 - binary_accuracy: 0.8810 - val_loss: 3.9108 - val_binary_accuracy: 0.6619\n",
      "Epoch 21/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.2955 - binary_accuracy: 0.8819 - val_loss: 3.8849 - val_binary_accuracy: 0.6596\n",
      "Epoch 22/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.2917 - binary_accuracy: 0.8825 - val_loss: 3.2180 - val_binary_accuracy: 0.7342\n",
      "Epoch 23/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.2887 - binary_accuracy: 0.8833 - val_loss: 2.7674 - val_binary_accuracy: 0.7650\n",
      "Epoch 24/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.2851 - binary_accuracy: 0.8848 - val_loss: 2.6124 - val_binary_accuracy: 0.8187\n",
      "Epoch 25/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.2839 - binary_accuracy: 0.8849 - val_loss: 3.6844 - val_binary_accuracy: 0.7186\n",
      "Epoch 26/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.2779 - binary_accuracy: 0.8873 - val_loss: 4.5242 - val_binary_accuracy: 0.6495\n",
      "Epoch 27/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.2772 - binary_accuracy: 0.8877 - val_loss: 1.9272 - val_binary_accuracy: 0.7654\n",
      "Epoch 28/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.2772 - binary_accuracy: 0.8869 - val_loss: 1.9978 - val_binary_accuracy: 0.8111\n",
      "Epoch 29/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.2729 - binary_accuracy: 0.8889 - val_loss: 8.0797 - val_binary_accuracy: 0.4233\n",
      "Epoch 30/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.2714 - binary_accuracy: 0.8895 - val_loss: 2.0867 - val_binary_accuracy: 0.8514\n",
      "Epoch 31/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.2677 - binary_accuracy: 0.8907 - val_loss: 2.4216 - val_binary_accuracy: 0.7782\n",
      "Epoch 32/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.2642 - binary_accuracy: 0.8927 - val_loss: 4.1096 - val_binary_accuracy: 0.6672\n",
      "Epoch 33/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.2660 - binary_accuracy: 0.8919 - val_loss: 1.5302 - val_binary_accuracy: 0.8286\n",
      "Epoch 34/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.2602 - binary_accuracy: 0.8940 - val_loss: 3.1545 - val_binary_accuracy: 0.7604\n",
      "Epoch 35/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.2596 - binary_accuracy: 0.8948 - val_loss: 3.7358 - val_binary_accuracy: 0.6870\n",
      "Epoch 36/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.2572 - binary_accuracy: 0.8965 - val_loss: 5.6910 - val_binary_accuracy: 0.5406\n",
      "Epoch 37/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.2529 - binary_accuracy: 0.8977 - val_loss: 9.5262 - val_binary_accuracy: 0.3444\n",
      "Epoch 38/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.2504 - binary_accuracy: 0.8989 - val_loss: 3.6583 - val_binary_accuracy: 0.6438\n",
      "Epoch 39/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.2446 - binary_accuracy: 0.9018 - val_loss: 3.8762 - val_binary_accuracy: 0.6770\n",
      "Epoch 40/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.2491 - binary_accuracy: 0.8987 - val_loss: 1.3375 - val_binary_accuracy: 0.8234\n",
      "Epoch 41/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.2433 - binary_accuracy: 0.9012 - val_loss: 3.2457 - val_binary_accuracy: 0.7155\n",
      "Epoch 42/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.2469 - binary_accuracy: 0.8998 - val_loss: 12.0429 - val_binary_accuracy: 0.2190\n",
      "Epoch 43/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.2431 - binary_accuracy: 0.9015 - val_loss: 3.4500 - val_binary_accuracy: 0.6638\n",
      "Epoch 44/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.2329 - binary_accuracy: 0.9057 - val_loss: 8.9843 - val_binary_accuracy: 0.3618\n",
      "Epoch 45/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.2305 - binary_accuracy: 0.9075 - val_loss: 3.8661 - val_binary_accuracy: 0.6216\n",
      "Epoch 46/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.2321 - binary_accuracy: 0.9064 - val_loss: 2.5563 - val_binary_accuracy: 0.7885\n",
      "Epoch 47/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.2295 - binary_accuracy: 0.9077 - val_loss: 1.4683 - val_binary_accuracy: 0.8240\n",
      "Epoch 48/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.2250 - binary_accuracy: 0.9090 - val_loss: 2.8934 - val_binary_accuracy: 0.7325\n",
      "Epoch 49/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.2219 - binary_accuracy: 0.9106 - val_loss: 6.1914 - val_binary_accuracy: 0.5096\n",
      "Epoch 50/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.2185 - binary_accuracy: 0.9131 - val_loss: 4.0353 - val_binary_accuracy: 0.6260\n",
      "Epoch 51/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.2192 - binary_accuracy: 0.9117 - val_loss: 3.8344 - val_binary_accuracy: 0.6249\n",
      "Epoch 52/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.2114 - binary_accuracy: 0.9141 - val_loss: 1.9079 - val_binary_accuracy: 0.7357\n",
      "Epoch 53/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.2095 - binary_accuracy: 0.9163 - val_loss: 5.5400 - val_binary_accuracy: 0.5351\n",
      "Epoch 54/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.2085 - binary_accuracy: 0.9161 - val_loss: 2.8038 - val_binary_accuracy: 0.7101\n",
      "Epoch 55/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.2063 - binary_accuracy: 0.9168 - val_loss: 2.6036 - val_binary_accuracy: 0.7189\n",
      "Epoch 56/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.2054 - binary_accuracy: 0.9176 - val_loss: 3.4693 - val_binary_accuracy: 0.6512\n",
      "Epoch 57/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.2028 - binary_accuracy: 0.9192 - val_loss: 2.3050 - val_binary_accuracy: 0.7275\n",
      "Epoch 58/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1989 - binary_accuracy: 0.9197 - val_loss: 1.7140 - val_binary_accuracy: 0.7645\n",
      "Epoch 59/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.2035 - binary_accuracy: 0.9184 - val_loss: 5.7771 - val_binary_accuracy: 0.5461\n",
      "Epoch 60/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.2012 - binary_accuracy: 0.9197 - val_loss: 7.1230 - val_binary_accuracy: 0.4740\n",
      "Epoch 61/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1990 - binary_accuracy: 0.9196 - val_loss: 0.6813 - val_binary_accuracy: 0.8530\n",
      "Epoch 62/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1971 - binary_accuracy: 0.9212 - val_loss: 5.4866 - val_binary_accuracy: 0.5526\n",
      "Epoch 63/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1974 - binary_accuracy: 0.9202 - val_loss: 6.6876 - val_binary_accuracy: 0.4866\n",
      "Epoch 64/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.2118 - binary_accuracy: 0.9149 - val_loss: 0.5835 - val_binary_accuracy: 0.8373\n",
      "Epoch 65/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.2240 - binary_accuracy: 0.9103 - val_loss: 1.9940 - val_binary_accuracy: 0.7287\n",
      "Epoch 66/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.2062 - binary_accuracy: 0.9166 - val_loss: 5.3322 - val_binary_accuracy: 0.5690\n",
      "Epoch 67/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.2023 - binary_accuracy: 0.9190 - val_loss: 5.7054 - val_binary_accuracy: 0.5284\n",
      "Epoch 68/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1954 - binary_accuracy: 0.9223 - val_loss: 4.7914 - val_binary_accuracy: 0.5746\n",
      "Epoch 69/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.1944 - binary_accuracy: 0.9222 - val_loss: 3.4558 - val_binary_accuracy: 0.6446\n",
      "Epoch 70/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1920 - binary_accuracy: 0.9225 - val_loss: 1.5722 - val_binary_accuracy: 0.7681\n",
      "Epoch 71/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1884 - binary_accuracy: 0.9252 - val_loss: 2.2080 - val_binary_accuracy: 0.7233\n",
      "Epoch 72/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1879 - binary_accuracy: 0.9250 - val_loss: 10.4026 - val_binary_accuracy: 0.2912\n",
      "Epoch 73/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1912 - binary_accuracy: 0.9233 - val_loss: 4.3498 - val_binary_accuracy: 0.6270\n",
      "Epoch 74/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1966 - binary_accuracy: 0.9202 - val_loss: 2.5991 - val_binary_accuracy: 0.7399\n",
      "Epoch 75/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1932 - binary_accuracy: 0.9209 - val_loss: 0.9703 - val_binary_accuracy: 0.8452\n",
      "Epoch 76/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1894 - binary_accuracy: 0.9238 - val_loss: 4.8518 - val_binary_accuracy: 0.5813\n",
      "Epoch 77/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1843 - binary_accuracy: 0.9247 - val_loss: 3.8181 - val_binary_accuracy: 0.6639\n",
      "Epoch 78/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1844 - binary_accuracy: 0.9248 - val_loss: 1.8208 - val_binary_accuracy: 0.7875\n",
      "Epoch 79/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1858 - binary_accuracy: 0.9248 - val_loss: 3.3128 - val_binary_accuracy: 0.6870\n",
      "Epoch 80/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1792 - binary_accuracy: 0.9283 - val_loss: 2.7498 - val_binary_accuracy: 0.7139\n",
      "Epoch 81/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1850 - binary_accuracy: 0.9254 - val_loss: 0.8571 - val_binary_accuracy: 0.8390\n",
      "Epoch 82/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1793 - binary_accuracy: 0.9281 - val_loss: 3.3486 - val_binary_accuracy: 0.6882\n",
      "Epoch 83/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1739 - binary_accuracy: 0.9299 - val_loss: 2.2007 - val_binary_accuracy: 0.7522\n",
      "Epoch 84/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1753 - binary_accuracy: 0.9291 - val_loss: 0.3365 - val_binary_accuracy: 0.8798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1714 - binary_accuracy: 0.9315 - val_loss: 2.7936 - val_binary_accuracy: 0.7155\n",
      "Epoch 86/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.1786 - binary_accuracy: 0.9287 - val_loss: 0.4444 - val_binary_accuracy: 0.8549\n",
      "Epoch 87/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1734 - binary_accuracy: 0.9306 - val_loss: 0.7962 - val_binary_accuracy: 0.8481\n",
      "Epoch 88/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1759 - binary_accuracy: 0.9285 - val_loss: 0.3877 - val_binary_accuracy: 0.8668\n",
      "Epoch 89/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1760 - binary_accuracy: 0.9293 - val_loss: 0.6203 - val_binary_accuracy: 0.8469\n",
      "Epoch 90/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1764 - binary_accuracy: 0.9276 - val_loss: 0.6071 - val_binary_accuracy: 0.8553\n",
      "Epoch 91/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.1845 - binary_accuracy: 0.9238 - val_loss: 0.4463 - val_binary_accuracy: 0.8597\n",
      "Epoch 92/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1793 - binary_accuracy: 0.9269 - val_loss: 5.5322 - val_binary_accuracy: 0.5763\n",
      "Epoch 93/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1766 - binary_accuracy: 0.9275 - val_loss: 1.0784 - val_binary_accuracy: 0.8175\n",
      "Epoch 94/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1795 - binary_accuracy: 0.9253 - val_loss: 0.4918 - val_binary_accuracy: 0.8518\n",
      "Epoch 95/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.1746 - binary_accuracy: 0.9288 - val_loss: 0.4635 - val_binary_accuracy: 0.8547\n",
      "Epoch 96/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1717 - binary_accuracy: 0.9298 - val_loss: 0.5244 - val_binary_accuracy: 0.8573\n",
      "Epoch 97/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1770 - binary_accuracy: 0.9282 - val_loss: 0.4108 - val_binary_accuracy: 0.8715\n",
      "Epoch 98/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1648 - binary_accuracy: 0.9341 - val_loss: 0.7340 - val_binary_accuracy: 0.8467\n",
      "Epoch 99/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1632 - binary_accuracy: 0.9336 - val_loss: 1.5647 - val_binary_accuracy: 0.8040\n",
      "Epoch 100/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1625 - binary_accuracy: 0.9345 - val_loss: 0.4416 - val_binary_accuracy: 0.8658\n",
      "Epoch 101/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1606 - binary_accuracy: 0.9342 - val_loss: 2.3852 - val_binary_accuracy: 0.7458\n",
      "Epoch 102/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1590 - binary_accuracy: 0.9363 - val_loss: 2.7078 - val_binary_accuracy: 0.7338\n",
      "Epoch 103/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1576 - binary_accuracy: 0.9362 - val_loss: 0.7692 - val_binary_accuracy: 0.8336\n",
      "Epoch 104/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1615 - binary_accuracy: 0.9341 - val_loss: 3.4631 - val_binary_accuracy: 0.6931\n",
      "Epoch 105/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1569 - binary_accuracy: 0.9366 - val_loss: 0.4483 - val_binary_accuracy: 0.8604\n",
      "Epoch 106/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1576 - binary_accuracy: 0.9362 - val_loss: 1.7619 - val_binary_accuracy: 0.7825\n",
      "Epoch 107/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1556 - binary_accuracy: 0.9373 - val_loss: 0.3531 - val_binary_accuracy: 0.8845\n",
      "Epoch 108/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1533 - binary_accuracy: 0.9385 - val_loss: 0.6843 - val_binary_accuracy: 0.8564\n",
      "Epoch 109/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1518 - binary_accuracy: 0.9388 - val_loss: 0.5665 - val_binary_accuracy: 0.8643\n",
      "Epoch 110/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1499 - binary_accuracy: 0.9397 - val_loss: 0.5737 - val_binary_accuracy: 0.8588\n",
      "Epoch 111/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1497 - binary_accuracy: 0.9399 - val_loss: 9.5665 - val_binary_accuracy: 0.3635\n",
      "Epoch 112/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.1514 - binary_accuracy: 0.9394 - val_loss: 4.3716 - val_binary_accuracy: 0.6401\n",
      "Epoch 113/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1568 - binary_accuracy: 0.9364 - val_loss: 8.0829 - val_binary_accuracy: 0.4469\n",
      "Epoch 114/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1492 - binary_accuracy: 0.9395 - val_loss: 4.4431 - val_binary_accuracy: 0.6343\n",
      "Epoch 115/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1454 - binary_accuracy: 0.9419 - val_loss: 0.4612 - val_binary_accuracy: 0.8700\n",
      "Epoch 116/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.1443 - binary_accuracy: 0.9422 - val_loss: 0.3353 - val_binary_accuracy: 0.8839\n",
      "Epoch 117/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1456 - binary_accuracy: 0.9408 - val_loss: 2.7339 - val_binary_accuracy: 0.7302\n",
      "Epoch 118/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1446 - binary_accuracy: 0.9419 - val_loss: 0.3922 - val_binary_accuracy: 0.8685\n",
      "Epoch 119/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1416 - binary_accuracy: 0.9434 - val_loss: 0.4999 - val_binary_accuracy: 0.8652\n",
      "Epoch 120/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1407 - binary_accuracy: 0.9438 - val_loss: 0.6681 - val_binary_accuracy: 0.8627\n",
      "Epoch 121/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1390 - binary_accuracy: 0.9444 - val_loss: 2.3539 - val_binary_accuracy: 0.7568\n",
      "Epoch 122/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1402 - binary_accuracy: 0.9440 - val_loss: 0.4375 - val_binary_accuracy: 0.8767\n",
      "Epoch 123/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1398 - binary_accuracy: 0.9435 - val_loss: 3.5402 - val_binary_accuracy: 0.7019\n",
      "Epoch 124/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1381 - binary_accuracy: 0.9455 - val_loss: 8.0340 - val_binary_accuracy: 0.4468\n",
      "Epoch 125/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1721 - binary_accuracy: 0.9310 - val_loss: 4.5850 - val_binary_accuracy: 0.6343\n",
      "Epoch 126/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1441 - binary_accuracy: 0.9424 - val_loss: 0.3884 - val_binary_accuracy: 0.8777\n",
      "Epoch 127/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1365 - binary_accuracy: 0.9457 - val_loss: 0.3721 - val_binary_accuracy: 0.8838\n",
      "Epoch 128/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1401 - binary_accuracy: 0.9445 - val_loss: 1.6576 - val_binary_accuracy: 0.8138\n",
      "Epoch 129/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.1305 - binary_accuracy: 0.9479 - val_loss: 0.8419 - val_binary_accuracy: 0.8291\n",
      "Epoch 130/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1307 - binary_accuracy: 0.9480 - val_loss: 0.3957 - val_binary_accuracy: 0.8845\n",
      "Epoch 131/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1306 - binary_accuracy: 0.9474 - val_loss: 1.0199 - val_binary_accuracy: 0.8415\n",
      "Epoch 132/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1277 - binary_accuracy: 0.9490 - val_loss: 1.8656 - val_binary_accuracy: 0.7995\n",
      "Epoch 133/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.1287 - binary_accuracy: 0.9489 - val_loss: 2.3475 - val_binary_accuracy: 0.7728\n",
      "Epoch 134/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1280 - binary_accuracy: 0.9494 - val_loss: 3.3066 - val_binary_accuracy: 0.7267\n",
      "Epoch 135/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1259 - binary_accuracy: 0.9506 - val_loss: 0.3667 - val_binary_accuracy: 0.8803\n",
      "Epoch 136/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1329 - binary_accuracy: 0.9461 - val_loss: 0.7033 - val_binary_accuracy: 0.8660\n",
      "Epoch 137/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.1267 - binary_accuracy: 0.9494 - val_loss: 2.0619 - val_binary_accuracy: 0.7859\n",
      "Epoch 138/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1259 - binary_accuracy: 0.9499 - val_loss: 1.2337 - val_binary_accuracy: 0.8346\n",
      "Epoch 139/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1242 - binary_accuracy: 0.9504 - val_loss: 0.9331 - val_binary_accuracy: 0.8506\n",
      "Epoch 140/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1264 - binary_accuracy: 0.9506 - val_loss: 0.5385 - val_binary_accuracy: 0.8767\n",
      "Epoch 141/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.1219 - binary_accuracy: 0.9511 - val_loss: 2.7360 - val_binary_accuracy: 0.7449\n",
      "Epoch 142/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1212 - binary_accuracy: 0.9523 - val_loss: 2.8252 - val_binary_accuracy: 0.7418\n",
      "Epoch 143/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1237 - binary_accuracy: 0.9513 - val_loss: 0.5085 - val_binary_accuracy: 0.8737\n",
      "Epoch 144/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1161 - binary_accuracy: 0.9552 - val_loss: 0.3967 - val_binary_accuracy: 0.8717\n",
      "Epoch 145/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1184 - binary_accuracy: 0.9532 - val_loss: 1.0186 - val_binary_accuracy: 0.8443\n",
      "Epoch 146/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1218 - binary_accuracy: 0.9513 - val_loss: 1.8314 - val_binary_accuracy: 0.8046\n",
      "Epoch 147/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1159 - binary_accuracy: 0.9544 - val_loss: 1.1366 - val_binary_accuracy: 0.8398\n",
      "Epoch 148/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1172 - binary_accuracy: 0.9541 - val_loss: 1.1774 - val_binary_accuracy: 0.8340\n",
      "Epoch 149/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1343 - binary_accuracy: 0.9465 - val_loss: 0.5664 - val_binary_accuracy: 0.8754\n",
      "Epoch 150/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.1247 - binary_accuracy: 0.9502 - val_loss: 0.3438 - val_binary_accuracy: 0.8878\n",
      "Epoch 151/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1224 - binary_accuracy: 0.9512 - val_loss: 0.4865 - val_binary_accuracy: 0.8794\n",
      "Epoch 152/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1255 - binary_accuracy: 0.9504 - val_loss: 0.3399 - val_binary_accuracy: 0.8836\n",
      "Epoch 153/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1282 - binary_accuracy: 0.9486 - val_loss: 0.3572 - val_binary_accuracy: 0.8815\n",
      "Epoch 154/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.1277 - binary_accuracy: 0.9495 - val_loss: 0.5493 - val_binary_accuracy: 0.8761\n",
      "Epoch 155/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1160 - binary_accuracy: 0.9548 - val_loss: 0.5786 - val_binary_accuracy: 0.8716\n",
      "Epoch 156/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1135 - binary_accuracy: 0.9552 - val_loss: 0.4002 - val_binary_accuracy: 0.8809\n",
      "Epoch 157/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1138 - binary_accuracy: 0.9550 - val_loss: 3.2644 - val_binary_accuracy: 0.7309\n",
      "Epoch 158/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1127 - binary_accuracy: 0.9557 - val_loss: 0.3335 - val_binary_accuracy: 0.8913\n",
      "Epoch 159/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1124 - binary_accuracy: 0.9557 - val_loss: 2.3533 - val_binary_accuracy: 0.7853\n",
      "Epoch 160/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1110 - binary_accuracy: 0.9562 - val_loss: 0.5551 - val_binary_accuracy: 0.8728\n",
      "Epoch 161/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1078 - binary_accuracy: 0.9576 - val_loss: 0.3350 - val_binary_accuracy: 0.8869\n",
      "Epoch 162/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1085 - binary_accuracy: 0.9575 - val_loss: 0.9724 - val_binary_accuracy: 0.8591\n",
      "Epoch 163/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1114 - binary_accuracy: 0.9561 - val_loss: 0.4451 - val_binary_accuracy: 0.8897\n",
      "Epoch 164/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1067 - binary_accuracy: 0.9584 - val_loss: 0.4498 - val_binary_accuracy: 0.8783\n",
      "Epoch 165/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1084 - binary_accuracy: 0.9571 - val_loss: 0.3456 - val_binary_accuracy: 0.8883\n",
      "Epoch 166/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1077 - binary_accuracy: 0.9577 - val_loss: 0.9435 - val_binary_accuracy: 0.8662\n",
      "Epoch 167/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1082 - binary_accuracy: 0.9573 - val_loss: 0.4959 - val_binary_accuracy: 0.8867\n",
      "Epoch 168/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1141 - binary_accuracy: 0.9544 - val_loss: 3.5039 - val_binary_accuracy: 0.7670\n",
      "Epoch 169/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1111 - binary_accuracy: 0.9556 - val_loss: 0.4941 - val_binary_accuracy: 0.8861\n",
      "Epoch 170/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1075 - binary_accuracy: 0.9578 - val_loss: 0.9441 - val_binary_accuracy: 0.8712\n",
      "Epoch 171/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1043 - binary_accuracy: 0.9593 - val_loss: 1.3726 - val_binary_accuracy: 0.8543\n",
      "Epoch 172/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1092 - binary_accuracy: 0.9560 - val_loss: 0.6153 - val_binary_accuracy: 0.8869\n",
      "Epoch 173/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1305 - binary_accuracy: 0.9482 - val_loss: 3.0890 - val_binary_accuracy: 0.7628\n",
      "Epoch 174/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1147 - binary_accuracy: 0.9545 - val_loss: 0.3630 - val_binary_accuracy: 0.8946\n",
      "Epoch 175/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1044 - binary_accuracy: 0.9590 - val_loss: 0.3484 - val_binary_accuracy: 0.8938\n",
      "Epoch 176/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1015 - binary_accuracy: 0.9602 - val_loss: 0.6630 - val_binary_accuracy: 0.8791\n",
      "Epoch 177/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1028 - binary_accuracy: 0.9594 - val_loss: 1.4458 - val_binary_accuracy: 0.8389\n",
      "Epoch 178/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1005 - binary_accuracy: 0.9608 - val_loss: 0.5102 - val_binary_accuracy: 0.8871\n",
      "Epoch 179/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1036 - binary_accuracy: 0.9597 - val_loss: 0.3390 - val_binary_accuracy: 0.8938\n",
      "Epoch 180/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1021 - binary_accuracy: 0.9602 - val_loss: 1.3452 - val_binary_accuracy: 0.8504\n",
      "Epoch 181/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1244 - binary_accuracy: 0.9516 - val_loss: 0.3472 - val_binary_accuracy: 0.8933\n",
      "Epoch 182/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1233 - binary_accuracy: 0.9502 - val_loss: 9.6993 - val_binary_accuracy: 0.3496\n",
      "Epoch 183/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1230 - binary_accuracy: 0.9510 - val_loss: 0.3141 - val_binary_accuracy: 0.8971\n",
      "Epoch 184/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1214 - binary_accuracy: 0.9516 - val_loss: 0.3536 - val_binary_accuracy: 0.8854\n",
      "Epoch 185/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1257 - binary_accuracy: 0.9501 - val_loss: 0.8124 - val_binary_accuracy: 0.8701\n",
      "Epoch 186/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1173 - binary_accuracy: 0.9529 - val_loss: 0.5273 - val_binary_accuracy: 0.8830\n",
      "Epoch 187/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1139 - binary_accuracy: 0.9543 - val_loss: 0.4145 - val_binary_accuracy: 0.8908\n",
      "Epoch 188/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1073 - binary_accuracy: 0.9576 - val_loss: 0.4118 - val_binary_accuracy: 0.8938\n",
      "Epoch 189/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1012 - binary_accuracy: 0.9602 - val_loss: 0.3614 - val_binary_accuracy: 0.8927\n",
      "Epoch 190/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1000 - binary_accuracy: 0.9609 - val_loss: 0.3247 - val_binary_accuracy: 0.8933\n",
      "Epoch 191/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.0978 - binary_accuracy: 0.9618 - val_loss: 0.5492 - val_binary_accuracy: 0.8843\n",
      "Epoch 192/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.0979 - binary_accuracy: 0.9610 - val_loss: 0.3670 - val_binary_accuracy: 0.8903\n",
      "Epoch 193/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.0964 - binary_accuracy: 0.9625 - val_loss: 0.4574 - val_binary_accuracy: 0.8869\n",
      "Epoch 194/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.0984 - binary_accuracy: 0.9618 - val_loss: 0.3903 - val_binary_accuracy: 0.8902\n",
      "Epoch 195/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.0968 - binary_accuracy: 0.9614 - val_loss: 0.3249 - val_binary_accuracy: 0.8977\n",
      "Epoch 196/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.0973 - binary_accuracy: 0.9615 - val_loss: 0.4868 - val_binary_accuracy: 0.8866\n",
      "Epoch 197/200\n",
      "6122/6122 [==============================] - 24s 4ms/step - loss: 0.0981 - binary_accuracy: 0.9610 - val_loss: 0.3352 - val_binary_accuracy: 0.8935\n",
      "Epoch 198/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1122 - binary_accuracy: 0.9556 - val_loss: 0.3400 - val_binary_accuracy: 0.8907\n",
      "Epoch 199/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1133 - binary_accuracy: 0.9539 - val_loss: 0.4320 - val_binary_accuracy: 0.8900\n",
      "Epoch 200/200\n",
      "6122/6122 [==============================] - 23s 4ms/step - loss: 0.1067 - binary_accuracy: 0.9576 - val_loss: 0.4043 - val_binary_accuracy: 0.8949\n",
      "2019-04-09 17:34:42.241267\n",
      "model saved\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "batch_size =  16 #multiple of 1290/5 (recording length)\n",
    "nb_classes = 16\n",
    "rows, cols = 431, 128  \n",
    "\n",
    "trainlist,validationlist,testlist=fileLists()\n",
    "print('lists sorted')\n",
    "X_tr, Y_train = getData(trainlist)\n",
    "X_v, Y_val = getData(validationlist)\n",
    "X_te, Y_test = getData(testlist)\n",
    "print('data obtained')\n",
    "X_train=np.expand_dims(X_tr,axis=3)\n",
    "X_val=np.expand_dims(X_v,axis=3)\n",
    "X_test=np.expand_dims(X_te,axis=3)\n",
    "print(X_train.shape, X_val.shape, X_test.shape)\n",
    "print('data sorted')\n",
    "model = compileCRNN(cols,rows,nb_classes=nb_classes)\n",
    "print('model compiled')\n",
    "savemodelfilename='models\\\\multi_label.testsave'\n",
    "samples=(X_train.shape[0])\n",
    "print(datetime.now())\n",
    "models,histories= buildModel(savemodelfilename, samples,model,X_train,Y_train,X_val, Y_val)\n",
    "print(datetime.now())\n",
    "print('model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
