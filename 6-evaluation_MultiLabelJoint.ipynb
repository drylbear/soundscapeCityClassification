{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import  load_model\n",
    "from keras.utils import np_utils\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import sed_eval\n",
    "import dcase_util\n",
    "import pickle\n",
    "#%run shared_functions.ipynb\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validationfiles:  2518\n",
      "testfiles:  2518\n",
      "data obtained\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def getStackFeatMat(scene):\n",
    "    with open(scene, \"rb\" ) as scenesample:\n",
    "        l,fv = pickle.load(scenesample)\n",
    "    return fv,l\n",
    "\n",
    "def reduceLabels(labels):\n",
    "    r,c=labels.shape \n",
    "    npOfLabels=np.zeros(c)\n",
    "    for j in range(0,c):\n",
    "        if np.sum(labels[:,j])>0:\n",
    "            npOfLabels[j]=1\n",
    "    return npOfLabels\n",
    "\n",
    "\n",
    "def fileLists():\n",
    "    trainlist=[]\n",
    "    validationlist=[]\n",
    "    testlist=[]\n",
    "    evalSetupFiles='..\\\\..\\\\CASAdatasets\\\\DCASE18_ASCT1\\\\TUT-urban-acoustic-scenes-2018-development\\\\evaluation_setup\\\\*.txt'\n",
    "    txtfilelist=glob.glob(evalSetupFiles)\n",
    "    for txt in txtfilelist:\n",
    "        if '_location' not in txt:\n",
    "            continue\n",
    "        if 'train' in txt:\n",
    "            continue\n",
    "        with open(txt,'r') as evaltxtfile:\n",
    "            for line in evaltxtfile.readlines():\n",
    "                line=line.strip().split('\\t')[0]\n",
    "                if 'train' in txt:\n",
    "                    trainlist.append(line.replace('audio','logMelSpec').replace('.wav','_aggScenes.pckl').replace('/','\\\\'))\n",
    "                elif 'test' in txt:\n",
    "                    testlist.append(line.replace('audio','logMelSpec').replace('.wav','_aggScenes.pckl').replace('/','\\\\'))\n",
    "                else:\n",
    "                    validationlist.append(line.replace('audio','logMelSpec').replace('.wav','_aggScenes.pckl').replace('/','\\\\'))\n",
    "    print('validationfiles: ', str(len(validationlist)))\n",
    "    print('testfiles: ', str(len(testlist)))\n",
    "    return validationlist,testlist\n",
    "\n",
    "labelRef={'barcelona':0, 'helsinki':1, 'london':2, 'paris':3, 'stockholm':4, 'vienna':5, \n",
    "          'airport':6, 'shopping_mall':7,'metro_station':8,'street_pedestrian':9,'public_square':10,\n",
    "          'street_traffic':11,'tram':12,'bus':13,'metro':14,'park':15}\n",
    "\n",
    "nb_classes=len(labelRef.keys())\n",
    "def getData(flist):\n",
    "    pth='..\\\\..\\\\CASAdatasets\\\\DCASE18_ASCT1\\\\TUT-urban-acoustic-scenes-2018-development\\\\'\n",
    "    X_=np.zeros(((len(flist)),128,431))\n",
    "    Y_=np.zeros(((len(flist)),nb_classes))\n",
    "    for i,tfile in enumerate(flist):\n",
    "        with open(pth+tfile, \"rb\" ) as scenesample:\n",
    "            fv=pickle.load(scenesample)\n",
    "        X_[i,:,:]=fv\n",
    "        location=tfile.split('-')[1]\n",
    "        Y_[i,labelRef[location]]=1\n",
    "        scene=tfile.split('-')[0].replace('logMelSpec\\\\','')\n",
    "        Y_[i,labelRef[scene]]=1\n",
    "    return X_, Y_\n",
    "validationlist,testlist=fileLists()\n",
    "X_v, Y_val = getData(validationlist)\n",
    "X_te, Y_test = getData(testlist)\n",
    "print('data obtained')\n",
    "X_val=np.expand_dims(X_v,axis=3)\n",
    "X_test=np.expand_dims(X_te,axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2518/2518 [==============================] - ETA: 30 - ETA: 9 - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 3s 1ms/step\n",
      "['loss', 'binary_accuracy']\n",
      "[0.31405577326313289, 0.89706612386052054]\n"
     ]
    }
   ],
   "source": [
    "#evaluate performance of each model\n",
    "path='models\\\\multi_label.hdf5'\n",
    "model=load_model(path)\n",
    "nb_classes=16\n",
    "#predictions=np.zeros((Y_test.shape))\n",
    "#print(predictions.shape)\n",
    "#print('**')\n",
    "#predictions=model.predict(X_test, verbose=1, batch_size=8) #\n",
    "#asc(predictions,'test')\n",
    "#print(\"FIIIINESSSHED :-D\")\n",
    "\n",
    "evaluation=model.evaluate(X_test, Y_test, verbose=1,batch_size=16)\n",
    "print(model.metrics_names)\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'binary_accuracy']\n",
      "[0.31405577326313289, 0.89706612386052054]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(model.metrics_names)\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2518/2518 [==============================] - ETA: 31 - ETA: 10 - ETA: 7 - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 3s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions=model.predict(X_test, verbose=1, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2518, 16)\n"
     ]
    }
   ],
   "source": [
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both scene and city have to be correct, joint:\n",
      "*** ASC:\n",
      "correct scenes: 312\n",
      " Accuracy:\n",
      "0.12390786338363781\n",
      "location:\n",
      "*** ASC:\n",
      "correct scenes: 1076\n",
      " Accuracy:\n",
      "0.4273232724384432\n",
      "scene:\n",
      "*** ASC:\n",
      "correct scenes: 814\n",
      " Accuracy:\n",
      "0.3232724384432089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3232724384432089"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binarised = hv(predictions)\n",
    "print(\"Both scene and city have to be correct, joint:\")\n",
    "asc(binarised,Y_test, joint=True)\n",
    "print('location:')\n",
    "asc(binarised[:,0:6],Y_test[:,0:6])\n",
    "print('scene:')\n",
    "asc(binarised[:,6:],Y_test[:,6:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_4 to have shape (16,) but got array with shape (10,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-c75624295c2d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_test_s\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_test_l\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgetTaskSeparateData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mscene_evaluation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_test_s\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[0mlocation_evaluation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_test_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\drbear\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[0;32m   1100\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1101\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1102\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Prepare inputs, delegate logic to `test_loop`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\drbear\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m                 exception_prefix='target')\n\u001b[0m\u001b[0;32m    790\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[1;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\drbear\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    136\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    139\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected dense_4 to have shape (16,) but got array with shape (10,)"
     ]
    }
   ],
   "source": [
    "locationLabelRef={'barcelona':0, 'helsinki':1, 'london':2, 'paris':3, 'stockholm':4, 'vienna':5}\n",
    "sceneLabelRef={'airport':0, 'shopping_mall':1,'metro_station':2,'street_pedestrian':3,'public_square':4,\n",
    "          'street_traffic':5,'tram':6,'bus':7,'metro':8,'park':9}\n",
    "\n",
    "nb_location_classes=len(locationLabelRef.keys())\n",
    "nb_scene_classes=len(sceneLabelRef.keys())\n",
    "\n",
    "def getTaskSeparateData(flist):\n",
    "    pth='..\\\\..\\\\CASAdatasets\\\\DCASE18_ASCT1\\\\TUT-urban-acoustic-scenes-2018-development\\\\'\n",
    "    X_=np.zeros(((len(flist)),128,431))\n",
    "    Y_s=np.zeros(((len(flist)),nb_scene_classes))\n",
    "    Y_l=np.zeros(((len(flist)),nb_location_classes))\n",
    "    for i,tfile in enumerate(flist):\n",
    "        with open(pth+tfile, \"rb\" ) as scenesample:\n",
    "            fv=pickle.load(scenesample)\n",
    "        X_[i,:,:]=fv\n",
    "        location=tfile.split('-')[1]\n",
    "        Y_l[i,locationLabelRef[location]]=1\n",
    "        scene=tfile.split('-')[0].replace('logMelSpec\\\\','')\n",
    "        Y_s[i,sceneLabelRef[scene]]=1\n",
    "    return X_,Y_s,Y_l\n",
    "X_test,Y_test_s,Y_test_l=getTaskSeparateData(testlist)\n",
    "X_test=np.expand_dims(X_test,axis=3)\n",
    "scene_evaluation=model.evaluate(X_test,Y_test_s,verbose=1,batch_size=32)\n",
    "location_evaluation=model.evaluate(X_test,Y_test_l,verbose=1,batch_size=32)\n",
    "print(model.metrics_names)\n",
    "print(scene_evaluation)\n",
    "print(location_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def hv(preds):\n",
    "    scene=[]\n",
    "    s,r=preds.shape\n",
    "    hv=np.zeros((s,r))\n",
    "    for i in range(0,s):\n",
    "        for j in range(0,r):\n",
    "             if preds[i,j]>globalthreshold:\n",
    "                hv[i,j]=1\n",
    "    return hv\n",
    "\n",
    "#print(predictions.shape)\n",
    "globalthreshold=0.4\n",
    "#test_scenes=hv(predictions)\n",
    "#print(test_scenes.shape)\n",
    "#print(sum(test_scenes))\n",
    "\n",
    "def asc(scene,Y_test,joint=False):\n",
    "    correct=0  \n",
    "    for idx,s in enumerate(scene):\n",
    "        \n",
    "        if joint:\n",
    "            match=0\n",
    "            for j,element in enumerate(s):\n",
    "                if element==Y_test[idx][j] and element==1:  #element is the predicted state e.g. 1 for present, is it also 1 in gt\n",
    "                    match=match+1\n",
    "            if match==2: #has matched both scene and location\n",
    "                correct=correct+1\n",
    "        else:\n",
    "            match=False\n",
    "            for j,element in enumerate(s):\n",
    "                if element==Y_test[idx][j] and element==1:  #element is the predicted state e.g. 1 for present, is it also 1 in gt\n",
    "                    match=True\n",
    "            if match: #has matched both scene and location\n",
    "                correct=correct+1\n",
    "    print('*** ASC:')\n",
    "    print('correct scenes: ' +str(correct)+ '\\n Accuracy:')\n",
    "    print(correct/Y_test.shape[0]) \n",
    "    return correct/Y_test.shape[0]\n",
    "\n",
    "#acc=asc(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def plot_confusion_matrix(mat, classes,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues,\n",
    "                          output = None):\n",
    "    \n",
    "    size = 3.5 + len(classes) * 0.5\n",
    "    plt.figure(figsize=(size, size))\n",
    "    plt.imshow(mat, interpolation='nearest', cmap=cmap)\n",
    "    #plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45, horizontalalignment='right')\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.0f' \n",
    "    thresh = mat.max() / 2.\n",
    "    for i, j in itertools.product(range(mat.shape[0]), range(mat.shape[1])):\n",
    "        plt.text(j, i, format(mat[i, j], fmt),\n",
    "                 horizontalalignment=\"center\", verticalalignment=\"center\",\n",
    "                 color=\"white\" if mat[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    #plt.ylabel('True label')\n",
    "    #plt.xlabel('Predicted label')\n",
    "    \n",
    "    if output is not None:\n",
    "        plt.savefig(output, bbox_inches='tight')\n",
    "        \n",
    "#strip out non-supermarket events\n",
    "\n",
    "scene_mat=np.random.randint(9, size=(6, 6)) #need actual class values for this!\n",
    "classes=[labelRef.keys()]\n",
    "plot_confusion_matrix(scene_mat, classes, title='', output='scenes.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
